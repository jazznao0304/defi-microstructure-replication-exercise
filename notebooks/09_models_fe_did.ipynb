{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d71f15-6bf3-4fa1-a811-12be07bd2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Setup\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Display options\n",
    "pd.set_option(\"display.width\", 160)\n",
    "pd.set_option(\"display.max_columns\", 80)\n",
    "\n",
    "ROOT = Path(\"..\")\n",
    "DATA = ROOT / \"data\"\n",
    "\n",
    "# Features input (from 07_build_features.ipynb)\n",
    "PROC_FEATURES = DATA / \"processed\" / \"features\"\n",
    "FEATURES_PATH = PROC_FEATURES / \"daily_features.parquet\"\n",
    "\n",
    "# Outputs\n",
    "OUT_MODELS  = ROOT / \"reports\" / \"models\"\n",
    "OUT_TABLES  = ROOT / \"reports\" / \"tables\" / \"models\"\n",
    "OUT_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "OUT_TABLES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Event dates\n",
    "EVENT_V3_LAUNCH = dt.date(2021, 5, 5)\n",
    "EVENT_FTX       = dt.date(2022, 11, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08caa82-d644-48ae-9591-9a629b163897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def write_model_outputs(res, name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Save a text summary and a tidy coefficient table.\n",
    "    Returns the tidy coef DataFrame.\n",
    "    \"\"\"\n",
    "    # Summary to text\n",
    "    with open(OUT_TABLES / f\"{name}_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(res.summary().as_text())\n",
    "\n",
    "    # Tidy coefs\n",
    "    coefs = (\n",
    "        pd.DataFrame({\n",
    "            \"term\": res.params.index,\n",
    "            \"estimate\": res.params.values,\n",
    "            \"std_error\": res.bse.values,\n",
    "            \"t_value\": res.tvalues.values,\n",
    "            \"p_value\": res.pvalues.values,\n",
    "        })\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    coefs.to_parquet(OUT_MODELS / f\"{name}_coefs.parquet\", index=False)\n",
    "    return coefs\n",
    "\n",
    "\n",
    "def fit_fe_ols(formula: str, data: pd.DataFrame, name: str, cluster_col: str = \"label\"):\n",
    "    \"\"\"\n",
    "    OLS with absorbed FE via categorical dummies in the formula.\n",
    "      - Use C(label) and C(date) for two-way FE.\n",
    "      - Cluster-robust SEs at cluster_col (default: label).\n",
    "    \"\"\"\n",
    "    # NA drop for used columns\n",
    "    # crude parse: collect tokens split by delimiters; ensures we drop NAs only on columns present\n",
    "    tokens = (\n",
    "        formula.replace(\"~\", \" \")\n",
    "               .replace(\"+\", \" \")\n",
    "               .replace(\"*\", \" \")\n",
    "               .replace(\":\", \" \")\n",
    "               .replace(\"(\", \" \")\n",
    "               .replace(\")\", \" \")\n",
    "               .split()\n",
    "    )\n",
    "    # keep plain column names only\n",
    "    base_cols = [t for t in tokens if t not in {\"C\", \"np.log\", \"I\"} and \"C(\" not in t and \"np.\" not in t and \"I(\" not in t]\n",
    "    # always ensure cluster_col present\n",
    "    use_cols = set([cluster_col, \"label\", \"date\"]).intersection(data.columns).union([c for c in base_cols if c in data.columns])\n",
    "    d = data.dropna(subset=list(use_cols)).copy()\n",
    "    if d.empty:\n",
    "        raise ValueError(f\"No rows left after NA-drop for variables: {sorted(use_cols)}\")\n",
    "\n",
    "    model = smf.ols(formula, data=d)\n",
    "    res = model.fit(cov_type=\"cluster\", cov_kwds={\"groups\": d[cluster_col]})\n",
    "    coefs = write_model_outputs(res, name)\n",
    "    print(f\"[OK] {name}  n={int(res.nobs)}  R2={res.rsquared:.3f}  → {name}_coefs.parquet, {name}_summary.txt\")\n",
    "    return res, coefs\n",
    "\n",
    "\n",
    "def add_event_time(df: pd.DataFrame, event_date: dt.date, col_name: str = \"tau\") -> pd.DataFrame:\n",
    "    \"\"\"Add integer event time τ = (date - event_date) in days.\"\"\"\n",
    "    d = df.copy()\n",
    "    d[col_name] = (pd.to_datetime(d[\"date\"]) - pd.to_datetime(event_date)).dt.days\n",
    "    return d\n",
    "\n",
    "\n",
    "def make_event_study_dummies(df: pd.DataFrame, tau_col: str, k_leads: int, k_lags: int, ref: int = -1):\n",
    "    \"\"\"\n",
    "    Build lead/lag dummies τ==k for k in [-k_leads, ..., -2, 0, ..., k_lags], omitting 'ref' (default -1).\n",
    "    Returns (df_with_dummies, list_of_dummy_names).\n",
    "    \"\"\"\n",
    "    d = df.copy()\n",
    "    ks = [k for k in range(-k_leads, k_lags + 1) if k != ref]\n",
    "    names = []\n",
    "    for k in ks:\n",
    "        nm = f\"D_tau_{k:+d}\".replace(\"+\", \"p\").replace(\"-\", \"m\")\n",
    "        d[nm] = (d[tau_col] == k).astype(int)\n",
    "        names.append(nm)\n",
    "    return d, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7cbb55-d9fd-4418-b7bc-218a925680e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[loaded] ..\\data\\processed\\features\\daily_features.parquet rows=67,910 from 2021-03-01 to 2023-02-28\n",
      "== Snapshot ==\n",
      "labels: 20 | venues: 9 | venue_types: ['CEX', 'DEX']\n",
      "date range: 2021-03-01 → 2023-02-28\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Load features\n",
    "# =========================\n",
    "assert FEATURES_PATH.exists(), f\"Missing features: {FEATURES_PATH}\"\n",
    "df = pd.read_parquet(FEATURES_PATH)\n",
    "print(f\"[loaded] {FEATURES_PATH} rows={len(df):,} from {df['date'].min()} to {df['date'].max()}\")\n",
    "\n",
    "# Safe numerics\n",
    "for c in [\"volumeUSD\", \"log_volumeUSD\", \"ret\", \"abs_ret\", \"v3_share\", \"v3_share_filled\",\n",
    "          \"eth_median_effective_gas_price_gwei\",\n",
    "          \"proxy_chl\",\"proxy_cs\",\"proxy_amihud\",\"proxy_roll\",\n",
    "          \"proxy_amihud_dex\",\"proxy_roll_dex\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Backfill a couple of convenience columns if missing\n",
    "if \"log_volumeUSD\" not in df.columns and \"volumeUSD\" in df.columns:\n",
    "    df[\"log_volumeUSD\"] = np.log(df[\"volumeUSD\"].clip(lower=1.0))\n",
    "if \"abs_ret\" not in df.columns and \"ret\" in df.columns:\n",
    "    df[\"abs_ret\"] = df[\"ret\"].abs()\n",
    "\n",
    "# Snapshot\n",
    "print(\"== Snapshot ==\")\n",
    "print(f\"labels: {df['label'].nunique()} | venues: {df['venue'].nunique()} | venue_types: {sorted(df['venue_type'].dropna().unique().tolist())}\")\n",
    "print(f\"date range: {df['date'].min()} → {df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980b8c88-0e13-49f8-8003-470397e648ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 750, but rank is 20\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] fe_logvol_v3share  n=39987  R2=0.355  → fe_logvol_v3share_coefs.parquet, fe_logvol_v3share_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 746, but rank is 15\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] fe_absret_v3share_cex  n=15766  R2=0.347  → fe_absret_v3share_cex_coefs.parquet, fe_absret_v3share_cex_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 746, but rank is 16\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] fe_cex_proxy_roll  n=10461  R2=0.614  → fe_cex_proxy_roll_coefs.parquet, fe_cex_proxy_roll_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 745, but rank is 16\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] fe_cex_proxy_chl  n=8110  R2=0.484  → fe_cex_proxy_chl_coefs.parquet, fe_cex_proxy_chl_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 746, but rank is 16\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] fe_cex_proxy_cs  n=15817  R2=0.590  → fe_cex_proxy_cs_coefs.parquet, fe_cex_proxy_cs_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 746, but rank is 16\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] fe_cex_proxy_amihud  n=15817  R2=0.173  → fe_cex_proxy_amihud_coefs.parquet, fe_cex_proxy_amihud_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 750, but rank is 19\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] fe_dex_proxy_amihud  n=39535  R2=0.018  → fe_dex_proxy_amihud_coefs.parquet, fe_dex_proxy_amihud_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 750, but rank is 20\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] fe_dex_proxy_roll  n=24173  R2=0.040  → fe_dex_proxy_roll_coefs.parquet, fe_dex_proxy_roll_summary.txt\n",
      "\n",
      "[FE registry]\n",
      "{'fe_logvol_v3share': {'nobs': 39987, 'r2': 0.35450832395772824}, 'fe_absret_v3share_cex': {'nobs': 15766, 'r2': 0.34668082008608136}, 'fe_cex_proxy_roll': {'nobs': 10461, 'r2': 0.6143700634752773}, 'fe_cex_proxy_chl': {'nobs': 8110, 'r2': 0.48421312958486684}, 'fe_cex_proxy_cs': {'nobs': 15817, 'r2': 0.5898203139778881}, 'fe_cex_proxy_amihud': {'nobs': 15817, 'r2': 0.1728997020480274}, 'fe_dex_proxy_amihud': {'nobs': 39535, 'r2': 0.018190514886500364}, 'fe_dex_proxy_roll': {'nobs': 24173, 'r2': 0.039907348873024384}}\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# FE panels (two–way FE)\n",
    "# =========================\n",
    "results_registry = {}\n",
    "\n",
    "# 1) DEX: log volume ~ v3_share + gas + FE(label,date)\n",
    "dex = df.loc[df[\"venue_type\"] == \"DEX\"].copy()\n",
    "need = {\"log_volumeUSD\",\"v3_share_filled\",\"eth_median_effective_gas_price_gwei\",\"label\",\"date\"}\n",
    "if need.issubset(dex.columns) and not dex.dropna(subset=list(need)).empty:\n",
    "    formula = \"log_volumeUSD ~ v3_share_filled + eth_median_effective_gas_price_gwei + C(label) + C(date)\"\n",
    "    res, coefs = fit_fe_ols(formula, dex, \"fe_logvol_v3share\")\n",
    "    results_registry[\"fe_logvol_v3share\"] = {\"nobs\": int(res.nobs), \"r2\": float(res.rsquared)}\n",
    "else:\n",
    "    print(\"[skip] fe_logvol_v3share: missing vars or empty after NA drop.\")\n",
    "\n",
    "# 2) CEX: |ret| ~ v3_share + gas + FE(label,date)  (tests cross-venue spillover)\n",
    "cex = df.loc[df[\"venue_type\"] == \"CEX\"].copy()\n",
    "need = {\"abs_ret\",\"v3_share_filled\",\"eth_median_effective_gas_price_gwei\",\"label\",\"date\"}\n",
    "if need.issubset(cex.columns) and not cex.dropna(subset=list(need)).empty:\n",
    "    formula = \"abs_ret ~ v3_share_filled + eth_median_effective_gas_price_gwei + C(label) + C(date)\"\n",
    "    res, coefs = fit_fe_ols(formula, cex, \"fe_absret_v3share_cex\")\n",
    "    results_registry[\"fe_absret_v3share_cex\"] = {\"nobs\": int(res.nobs), \"r2\": float(res.rsquared)}\n",
    "else:\n",
    "    print(\"[skip] fe_absret_v3share_cex: missing vars or empty after NA drop.\")\n",
    "\n",
    "# 3) CEX proxies ~ log volume + gas + FE(label,date)\n",
    "#    (run four separate regressions where available)\n",
    "for prox in [\"proxy_roll\",\"proxy_chl\",\"proxy_cs\",\"proxy_amihud\"]:\n",
    "    need = {\"log_volumeUSD\",\"eth_median_effective_gas_price_gwei\", prox, \"label\",\"date\"}\n",
    "    d = cex.copy()\n",
    "    if need.issubset(d.columns) and not d.dropna(subset=list(need)).empty:\n",
    "        formula = f\"{prox} ~ log_volumeUSD + eth_median_effective_gas_price_gwei + C(label) + C(date)\"\n",
    "        res, coefs = fit_fe_ols(formula, d, f\"fe_cex_{prox}\")\n",
    "        results_registry[f\"fe_cex_{prox}\"] = {\"nobs\": int(res.nobs), \"r2\": float(res.rsquared)}\n",
    "    else:\n",
    "        print(f\"[skip] fe_cex_{prox}: missing vars or empty after NA drop.\")\n",
    "\n",
    "# 4) DEX proxies (Amihud/Roll) ~ log volume + gas + FE(label,date)\n",
    "for prox in [\"proxy_amihud\", \"proxy_roll\", \"proxy_amihud_dex\", \"proxy_roll_dex\"]:\n",
    "    if prox not in dex.columns:\n",
    "        continue\n",
    "    need = {\"log_volumeUSD\",\"eth_median_effective_gas_price_gwei\", prox, \"label\",\"date\"}\n",
    "    d = dex.copy()\n",
    "    if need.issubset(d.columns) and not d.dropna(subset=list(need)).empty:\n",
    "        formula = f\"{prox} ~ log_volumeUSD + eth_median_effective_gas_price_gwei + C(label) + C(date)\"\n",
    "        res, coefs = fit_fe_ols(formula, d, f\"fe_dex_{prox}\")\n",
    "        results_registry[f\"fe_dex_{prox}\"] = {\"nobs\": int(res.nobs), \"r2\": float(res.rsquared)}\n",
    "    else:\n",
    "        print(f\"[skip] fe_dex_{prox}: missing vars or empty after NA drop.\")\n",
    "\n",
    "print(\"\\n[FE registry]\")\n",
    "print(results_registry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff07142-4906-4754-b1ed-326a1a578a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 752, but rank is 20\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] did1_v3launch_logvol_dex_vs_cex  n=55804  R2=0.494  → did1_v3launch_logvol_dex_vs_cex_coefs.parquet, did1_v3launch_logvol_dex_vs_cex_summary.txt\n",
      "[OK] did1_v3launch_eventstudy_logvol_dex_only  n=39987  R2=0.324  → did1_v3launch_eventstudy_logvol_dex_only_coefs.parquet, did1_v3launch_eventstudy_logvol_dex_only_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 80, but rank is 19\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# DiD #1 — Uniswap v3 launch (2021-05-05)\n",
    "# =========================\n",
    "\n",
    "# A) DEX vs CEX: log volume ~ DEX*Post + gas + FE(label,date)\n",
    "d = df.copy()\n",
    "d[\"is_dex\"] = (d[\"venue_type\"] == \"DEX\").astype(int)\n",
    "d[\"post_v3\"] = (pd.to_datetime(d[\"date\"]) >= pd.to_datetime(EVENT_V3_LAUNCH)).astype(int)\n",
    "\n",
    "need = {\"log_volumeUSD\",\"eth_median_effective_gas_price_gwei\",\"is_dex\",\"post_v3\",\"label\",\"date\"}\n",
    "if need.issubset(d.columns) and not d.dropna(subset=list(need)).empty:\n",
    "    formula = \"log_volumeUSD ~ is_dex * post_v3 + eth_median_effective_gas_price_gwei + C(label) + C(date)\"\n",
    "    res, coefs = fit_fe_ols(formula, d, \"did1_v3launch_logvol_dex_vs_cex\", cluster_col=\"label\")\n",
    "else:\n",
    "    print(\"[skip] did1_v3launch_logvol_dex_vs_cex: missing vars or empty after NA drop.\")\n",
    "\n",
    "# B) Event study (DEX only): drop daily FE to avoid perfect collinearity with event bins\n",
    "K = 30\n",
    "dex_es = df.loc[df[\"venue_type\"] == \"DEX\"].copy()\n",
    "dex_es = add_event_time(dex_es, EVENT_V3_LAUNCH, col_name=\"tau_v3\")\n",
    "dex_es, dummies = make_event_study_dummies(dex_es, \"tau_v3\", k_leads=K, k_lags=K, ref=-1)\n",
    "\n",
    "need = {\"log_volumeUSD\",\"eth_median_effective_gas_price_gwei\",\"label\"} | set(dummies)\n",
    "if need.issubset(dex_es.columns) and not dex_es.dropna(subset=list(need)).empty:\n",
    "    rhs = \" + \".join(dummies) + \" + eth_median_effective_gas_price_gwei + C(label)\"\n",
    "    formula = f\"log_volumeUSD ~ {rhs}\"\n",
    "    res, coefs = fit_fe_ols(formula, dex_es, \"did1_v3launch_eventstudy_logvol_dex_only\", cluster_col=\"label\")\n",
    "else:\n",
    "    print(\"[skip] did1_v3launch_eventstudy_logvol_dex_only: missing vars or empty after NA drop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c11da0-e90a-45ae-8137-1b7c474259a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 752, but rank is 20\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] did2_ftx_logvol_dex_vs_cex  n=55804  R2=0.493  → did2_ftx_logvol_dex_vs_cex_coefs.parquet, did2_ftx_logvol_dex_vs_cex_summary.txt\n",
      "[OK] did2_ftx_eventstudy_logvol_dex_only  n=39987  R2=0.319  → did2_ftx_eventstudy_logvol_dex_only_coefs.parquet, did2_ftx_eventstudy_logvol_dex_only_summary.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jazzn\\anaconda3\\envs\\mscqf-rep\\Lib\\site-packages\\statsmodels\\base\\model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 80, but rank is 19\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# DiD #2 — FTX collapse (2022-11-10)\n",
    "# =========================\n",
    "\n",
    "# A) DEX vs CEX: log volume ~ DEX*Post + gas + FE(label,date)\n",
    "d2 = df.copy()\n",
    "d2[\"is_dex\"] = (d2[\"venue_type\"] == \"DEX\").astype(int)\n",
    "d2[\"post_ftx\"] = (pd.to_datetime(d2[\"date\"]) >= pd.to_datetime(EVENT_FTX)).astype(int)\n",
    "\n",
    "need = {\"log_volumeUSD\",\"eth_median_effective_gas_price_gwei\",\"is_dex\",\"post_ftx\",\"label\",\"date\"}\n",
    "if need.issubset(d2.columns) and not d2.dropna(subset=list(need)).empty:\n",
    "    formula = \"log_volumeUSD ~ is_dex * post_ftx + eth_median_effective_gas_price_gwei + C(label) + C(date)\"\n",
    "    res, coefs = fit_fe_ols(formula, d2, \"did2_ftx_logvol_dex_vs_cex\", cluster_col=\"label\")\n",
    "else:\n",
    "    print(\"[skip] did2_ftx_logvol_dex_vs_cex: missing vars or empty after NA drop.\")\n",
    "\n",
    "# B) Event study (DEX only): drop daily FE to identify event-time bins\n",
    "K = 30\n",
    "dex_es2 = df.loc[df[\"venue_type\"] == \"DEX\"].copy()\n",
    "dex_es2 = add_event_time(dex_es2, EVENT_FTX, col_name=\"tau_ftx\")\n",
    "dex_es2, dummies2 = make_event_study_dummies(dex_es2, \"tau_ftx\", k_leads=K, k_lags=K, ref=-1)\n",
    "\n",
    "need = {\"log_volumeUSD\",\"eth_median_effective_gas_price_gwei\",\"label\"} | set(dummies2)\n",
    "if need.issubset(dex_es2.columns) and not dex_es2.dropna(subset=list(need)).empty:\n",
    "    rhs = \" + \".join(dummies2) + \" + eth_median_effective_gas_price_gwei + C(label)\"\n",
    "    formula = f\"log_volumeUSD ~ {rhs}\"\n",
    "    res, coefs = fit_fe_ols(formula, dex_es2, \"did2_ftx_eventstudy_logvol_dex_only\", cluster_col=\"label\")\n",
    "else:\n",
    "    print(\"[skip] did2_ftx_eventstudy_logvol_dex_only: missing vars or empty after NA drop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82f4309d-c73d-4ba0-b77f-a20095aee2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done] Models estimated. Coefficients saved in: ..\\reports\\models\n",
      "Summaries saved in: ..\\reports\\tables\\models\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Done\n",
    "# =========================\n",
    "print(f\"[Done] Models estimated. Coefficients saved in: {OUT_MODELS}\")\n",
    "print(f\"Summaries saved in: {OUT_TABLES}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mscqf-rep)",
   "language": "python",
   "name": "mscqf-rep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
